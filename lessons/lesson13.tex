\addcontentsline{toc}{chapter}{Занятие 13. Разложение Вольда. Задача прогноза.}
\chapter*{Занятие 13. Разложение Вольда. Задача прогноза.}

\addcontentsline{toc}{section}{Контрольные вопросы и задания}
\section*{Контрольные вопросы и задания}

\subsubsection*{Приведите определение сингулярной и регулярной стационарной последовательности,
                приведите примеры.}

Стационарная последовательность называется сингулярной, если
\begin{equation*}
  H_{-\infty }^{ \xi } =
  \dotsc =
  H_0^{ \xi } =
  \dotsc,
\end{equation*}
то есть если они все просто совпадают между собой, и называется регулярной,
если $H_{-\infty }^{ \xi } = \left\{ 0 \right\} $.

Примеры:
\begin{enumerate}
  \item если $ \left\{ \xi_n \right\} $~---~это последовательность случайных колебаний, то
  \begin{equation*}
    \mu =
    \sum \limits_{k = 1}^m \delta_{ \lambda_k}.
  \end{equation*}
  Прогноз: $ \hat{ \xi }_n = \xi_n$.

  Сейчас $H_n^{ \xi } = \overline{LS \left\{ \xi_k \right\} }, \, n \in \mathbb{Z}$.

  Нет зависимости от $n$, следовательно, $ \dotsc = H_n^{ \xi } = H_{n + 1}^{ \xi } = \dotsc $.

  Так как $H_n^{ \xi }$ не меняется, то
  \begin{equation*}
    \bigcap \limits_{n \in \mathbb{Z}} H_n^{ \xi } =
    H_0^{ \xi };
  \end{equation*}
  \item последовательность белого шума $ \left\{ \xi_n, \, n \in \mathbb{Z} \right\} $.
  У неё есть спектральная плотность $p \equiv 1$ на $ \left[ -\pi, \pi \right] $.
  В этом случае прогноза вообще никакого нет.
  Вместо проекции получаем $ \hat{ \xi }_n = 0$.

  Сейчас $H_n^{ \xi } = \overline{LS \left\{ \xi_k, \, k \leq n \right\} }$.

  Так как последовательность белого шума~---~ортонональные случайные величины,
  то $ \xi_{n + 1} \perp H_n^{ \xi }$.

  Следовательно, $H_n^{ \xi } \subset H_{n + 1}^{ \xi }$ (включение строгое).

  $H_n^{ \xi }$~---~это прошлое до момента времени $n$.

  Тогда
  \begin{equation*}
    \bigcap \limits_{n \in \mathbb{Z}} H_n^{ \xi } =
    \left\{ 0 \right\}.
  \end{equation*}

  Докажем это.
  Возьмём
  \begin{equation*}
    \zeta =
    \bigcap \limits_{n \in \mathbb{Z}} H_n^{ \xi } \equiv
    H_{-\infty }^{ \xi }.
  \end{equation*}
  Если $ \zeta $ принадлежит пересечению, то $ \zeta \in H_0^{ \xi }$.
  Раз так, то $ \zeta $ должно представляться как предел линейной комбинации
  \begin{equation*}
    \zeta =
    \lim \limits_{m \to \infty } \sum \limits_{k = -m}^0 c_{km} \zeta_k.
  \end{equation*}

  Замыканием такой линейной комбинации и есть $H_0^{ \xi }$.

  Одновременно с этим $ \zeta \in H_{-1}^{ \xi }$.
  Следовательно, $ \zeta \perp \xi_0$.
  Можем сделать заключение, что $ \zeta \in H_{-2}^{ \xi } \Rightarrow \zeta \perp \xi_{-1}$.

  Таким образом, $ \forall k \leq 0 \; : \; \zeta \perp \xi_k$.
  Отсюда
  \begin{equation*}
    M \left| \zeta \right|^2 =
    \lim \limits_{m \to \infty } M \zeta \cdot \overline{ \sum \limits_{k = -m}^0 c_{km} \zeta_k} =
    0
  \end{equation*}
  (так как $ \zeta $ ортогональная ко всем $ \xi_k$).

  Таким образом, $H_{-\infty }^{ \xi } = \left\{ 0 \right\} $.
\end{enumerate}

\subsubsection*{Опишите пространства, связанные со стационарной последовательностью.}

Будем использовать
$ \forall n \in \mathbb{Z} \; : \;
  H_n^{ \xi } = \overline{LS \left\{ \xi_k, \, k \leq n \right\} }$~---~замыкание
в среднем квадратическом линейной оболочки $ \left\{ \xi_k, \, k \leq n \right\} $.

Получили $H_n^{ \xi }$~---~подпространство пространства
$L_2 \left( \Omega, \mathcal{F}, P \right) $.

Пусть $Q_n$~---~это проектор на $H_n$.

\subsubsection*{Что такое разложение Вольда?}

Для произвольной стационарной последовательности $ \left\{ \xi_n \right\} $
существует регулярная последовательность $ \left\{ \xi_n' \right\} $
и сингулярная последовательность $ \left\{ \xi_n'' \right\} $ такие, что
\begin{enumerate}
  \item $ \xi_n = \xi_n' + \xi_n''$;
  \item $ \xi_n' \perp \xi_m'', \qquad \forall n, m \in \mathbb{Z}$;
  \item $ \xi_n', \xi_n'' \in H_n^{ \xi }$.
\end{enumerate}

Это представление называется разложением Вольда.

\subsubsection*{Как определяются прогноз и погрешность прогноза $ \xi_n, \, n \geq 1$ при
                $ \xi^0 = \left( \dotsc, \xi_{-1}, \xi_0 \right) $ с помощью разложения Вольда?}

Решение задачи прогноза:
\begin{equation*}
  Q_{n_0} \xi_n =
  \sum \limits_{k = n - n_0}^{ \infty } \alpha_k e_{n - k}.
\end{equation*}

Можем посчитать ошибку прогноза:
\begin{equation*}
  \left \Vert \xi_n - Q_{n_0} \xi_n \right \Vert^2 =
  \left \Vert \sum \limits_{k = 0}^{n - n_0 - 1} \alpha_k e_{n - k} \right \Vert^2 =
  \sum \limits_{k = 0}^{n - n_0 - 1} \left| \alpha_k \right|^2.
\end{equation*}

\subsubsection*{Запишите формулу для погрешности прогноза в терминах спектральной плотности.}

\begin{equation*}
  \sigma^2 =
  e^{ \frac{1}{2 \pi } \int \limits_{-\pi }^{ \pi } ln \, p \left( \lambda \right) d \lambda }.
\end{equation*}

\addcontentsline{toc}{section}{Аудиторные задачи}
\section*{Аудиторные задачи}

\subsubsection*{13.2}

\textit{Задание.}
Стационарная последовательность $ \left\{ \xi_n \right\}_{n \in \mathbb{Z}}$ задана соотношением
$ \xi_{n + 1} =
  3 \varepsilon_{n + 1} + \varepsilon_n$,
где $ \left\{ \varepsilon_n \right\}_{n \in \mathbb{Z}}$~---~белый шум.
Найдите оптимальную линейную оценку $ \xi_n$ при $ \xi^0 = \left( \dotsc, \xi_{-1}, \xi_0 \right) $
и погрешность прогноза $M \left( \xi_n - \hat{ \xi_n} \right)^2$.

\textit{Решение.}
$ \hat{ \xi_n}$~---~проекция $ \xi_n$ на $H_0^{ \xi }$.

Нужно знать базис в пространстве $H_0^{ \xi }$.

Если $ \varepsilon_n \in H_n^{ \xi }$,
то $ \varepsilon_0, \varepsilon_{-1}, \varepsilon_{-2}, \dotsc $~---~это
и будет ортонормированный базис в $H_0^{ \xi }$.
Можно ли $ \varepsilon_n$ переписать через $ \xi_n$?

Выразим из соотношения, которое задано в условии, $3 \varepsilon_n = \xi_n - \varepsilon_{n - 1}$,
откуда
\begin{equation*}
  \varepsilon_n =
  \frac{1}{3} \cdot \xi_n - \frac{1}{3} \cdot \varepsilon_{n - 1} =
  \frac{1}{3} \cdot \xi_n -
  \frac{1}{3} \cdot
  \left( \frac{1}{3} \cdot \xi_{n - 1} - \frac{1}{3} \cdot \varepsilon_{n - 2} \right) = \\
\end{equation*}
Раскроем скобки
\begin{equation*}
  = \frac{1}{3} \cdot \xi_n - \frac{1}{9} \cdot \xi_{n - 1} + \frac{1}{9} \cdot \varepsilon_{n - 2} =
  \dotsc =
  \sum \limits_{k = 0}^{N - 1} \left( -1 \right)^k \cdot \frac{1}{3^{k + 1}} \cdot \xi_{n - k} +
  \frac{ \varepsilon_{n - N}}{3^N} \cdot \left( -1 \right)^N.
\end{equation*}
Второе слагаемое стремится к нулю при $N \to \infty $, потому что его длина~---~это
\begin{equation*}
  \frac{1}{3^N}.
\end{equation*}

Тогда
\begin{equation*}
  \varepsilon_n =
  \sum \limits_{k = 0}^{ \infty } \frac{ \left( -1 \right)^k}{3^{k + 1}} \cdot \xi_{n - k} \in
  H_n^{ \xi }.
\end{equation*}
Вывод такой, что у нас появился ортономированный базис в
$H_0^{ \xi } \,
  \left\{ \varepsilon_k, \, k \leq 0 \right\} $.

Значит, мы можем посчитать проекцию
\begin{equation*}
  \hat{ \xi_n} =
  \sum \limits_{k = -\infty }^0 \left( \xi_n, \varepsilon_k \right) \varepsilon_k.
\end{equation*}
Чтобы получить ответ, нужно найти ковариацию, то есть
\begin{equation*}
  \left( \xi_n, \varepsilon_k \right) =
  3 \left( \varepsilon_n, \varepsilon_k \right) +
  \left( \varepsilon_{n - 1}, \varepsilon_k \right) =
\end{equation*}
Первое слагаемое равно нулю
\begin{equation*}
  = \begin{cases}
    1, \qquad n = 1, \, k = 0, \\
    0, \qquad otherwise.
  \end{cases}
\end{equation*}

Говорили, что $n \geq 1$, а $k \leq 0$.

Теперь получается ответ.
Если хотим спрогнозировать $ \xi_n$ при $n \geq 2$, то $ \hat{ \xi_n} = 0$.
Значит, ошибка прогноза
\begin{equation*}
  M \left( \xi_n - \hat{ \xi_n} \right)^2 =
  M \xi_n^2 =
  M \left( 3 \varepsilon_n + \varepsilon_{n - 1} \right)^2 =
\end{equation*}
По теореме Пифагора
\begin{equation*}
  = 9 + 1 =
  10.
\end{equation*}
Если $n = 1$, то
\begin{equation*}
  \hat{ \xi_1} =
  \varepsilon_0 =
  \sum \limits_{k = 0}^{ \infty } \left( -1 \right)^k \cdot \frac{1}{3^{k + 1}} \cdot \xi_{-k}.
\end{equation*}
Значит,
ошибка прогноза $M \left( \xi_1 - \hat{ \xi_1} \right)^2 = M \left( 3 \varepsilon_1 \right)^2 = 9$.
Решили задачу прогноза.

\subsubsection*{13.3}

\textit{Задание.}
Стационарная последовательность $ \left\{ \xi_n \right\}_{n \in \mathbb{Z}}$
удовлетворяет уравнению $ \xi_{n + 1} = 3 \xi_n + \varepsilon_n$,
где $ \left\{ \varepsilon_n \right\}_{n \in \mathbb{Z}}$~---~белый шум.
Найдите оптимальную линейную оценку $ \xi_n$ при $ \xi^0 = \left( \dotsc, \xi_{-1}, \xi_0 \right) $
и погрешность прогноза $M \left( \xi_n - \hat{ \xi }_n \right)^2$.

\textit{Решение.}
Нужно сначала понять, как устроено пространство $H_0^{ \xi }$,
то есть нужно найти ортонормированный базис в этом пространстве.

$ \xi_n =
  2 \xi_{n - 1} + \varepsilon_{n - 1} =
  4 \xi_{n - 2} + 2 \varepsilon_{n - 2} + \varepsilon_{n - 1}$,
но так сейчас плохо делать, потому что длина остатка стремится к бесконечности.
$ \xi_{n + 3} = 2 \xi_{n + 2} + \varepsilon_{n + 2}$, откуда
\begin{equation*}
  \xi_{n + 1} =
  \frac{1}{2} \cdot \xi_{n + 3} - \frac{1}{2} \cdot \varepsilon_{n + 2}.
\end{equation*}

Тогда
\begin{equation*}
  \xi_n =
  \frac{ \xi_{n + 1}}{2} - \frac{ \varepsilon_n}{2} =
  \frac{1}{2} \cdot
  \left( \frac{1}{2} \cdot \xi_{n + 2} - \frac{1}{2} \cdot \varepsilon_{n + 1 } \right) -
  \frac{1}{2} \cdot \varepsilon_n =
  \frac{1}{4} \cdot \xi_{n + 2} - \frac{1}{4} \cdot \varepsilon_{n + 1} -
  \frac{1}{2} \cdot \varepsilon_n =
\end{equation*}
За $N$ шагов получим
\begin{equation*}
  = -\sum \limits_{k = 0}^{N - 1} \frac{1}{2^{k + 1}} \cdot \varepsilon_{n + k} +
  \frac{ \varepsilon_{n + N}}{2^N}.
\end{equation*}
Второе слагаемое сходится к нулю, значит, мы нашли $ \xi $.

Сейчас
\begin{equation*}
  \xi_n =
  -\sum \limits_{k = 0}^{ \infty } \frac{1}{2^{k + 1}} \cdot \varepsilon_{n + k}.
\end{equation*}

Как построить ортонормированный базис в $H_0^{ \xi }$?
Напомним, что
\begin{equation*}
  H_n^{ \xi } =
  \overline{LS \left\{ \dotsc, \xi_{-2}, \xi_{-1}, \xi_0 \right\} }.
\end{equation*}

Знаем, что $ \xi_{n + 1} = 2 \xi_n + \varepsilon_n$.
Используем ортогонализацию Грама-Шмидта.
По условию
\begin{equation*}
  \xi_0 =
  2 \xi_{n - 1} + \varepsilon_{-1} =
  -\left( \frac{1}{2} \cdot \varepsilon_0 + \frac{1}{4} \cdot \varepsilon_1 + \dotsc \right).
\end{equation*}

Как организовать $ \xi_{-1}$?

Получаем
\begin{equation*}
  \xi_{-1} =
  -\left(
    \frac{1}{2} \cdot \varepsilon_{-1} + \frac{1}{4} \cdot \varepsilon_0 +
    \frac{1}{8} \cdot \varepsilon_1 + \dotsc
  \right),
\end{equation*}
где
\begin{equation*}
  \frac{1}{4} \cdot \varepsilon_0 + \frac{1}{8} \cdot \varepsilon_1 + \dotsc =
  -\frac{1}{2} \cdot \xi_0.
\end{equation*}
Слагаемое
\begin{equation*}
  -\frac{1}{2} \cdot \varepsilon_{-1}
\end{equation*}
это ортогональная составляющая $ \xi_{-1}$ до $ \xi_0$.

Ортонормированный базис тогда будет таким:
$ \sqrt{3} \xi_0, \varepsilon_{-1}, \varepsilon_{-2}, \varepsilon_{-3}, \dotsc $.

Посчитаем длину $ \xi_0$.
Получим
\begin{equation*}
  \left \Vert \xi_0 \right \Vert^2 =
  \sum \limits_{k = 0}^{ \infty } \frac{1}{4^{k + 1}} =
  \frac{ \frac{1}{4}}{1 - \frac{1}{4}} =
  \frac{1}{3}.
\end{equation*}

Запишем прогноз
\begin{equation*}
  \hat{ \xi }_n =
  3 \left( \xi_n, \xi_0 \right) \xi_0 + \left( \xi_n, \varepsilon_{-1} \right) \varepsilon_{-1} +
  \left( \xi_n, \varepsilon_{-2} \right) \varepsilon_{-2} + \dotsc =
\end{equation*}
Все слагаемые, начиная со второго, равны нулю.
Здесь $n \geq 1$.
Получаем
\begin{equation*}
  = 3 \left( \xi_n, \xi_0 \right) \xi_0.
\end{equation*}

Найдём отдельно
\begin{equation*}
  \left( \xi_n, \xi_0 \right) =
  \left(
    -\sum \limits_{k = 0}^{ \infty } \varepsilon_{n + 2} \cdot \frac{1}{2^{k + 1}},
    -\sum \limits_{j = 0}^{ \infty } \frac{ \varepsilon_j}{2^{j + 1}}
  \right) =
\end{equation*}
Двойные суммы выносятся
\begin{equation*}
  = \sum \limits_{k, j = 0}^{ \infty }
    \frac{1}{2^{k + j + 2}} \left( \varepsilon_{n + k}, \varepsilon_j \right) =
\end{equation*}
Скалярное произведение равно единице, когда индексы совпадают, то есть $k = j - n$.
Вместо двойной суммы остаётся одинарная сумма
\begin{equation*}
  = \sum \limits_{j = n}^{ \infty } \frac{1}{2^{2j - n + 2}} =
  2^{n - 2} \sum \limits_{j = n}^{ \infty } \frac{1}{4j} =
  2^{n - 2} \cdot \frac{ \frac{1}{4^n}}{1 - \frac{1}{4}} =
  \frac{1}{3 \cdot 2^n}.
\end{equation*}

Подставляем скалярное произведение в формулу и получим ответ
\begin{equation*}
  \hat{ \xi }_n = \frac{ \xi_0}{2^n}, \,
  n \geq 1.
\end{equation*}
Это оптимальный прогноз.

Найдём ошибку прогноза по теореме Пифагора
\begin{equation*}
  M \left| \xi_n - \hat{ \xi }_n \right|^2 =
  M \xi_n^2 - M \hat{ \xi }_n^2 =
  \frac{1}{3} - \frac{1}{3 \cdot 4^n}.
\end{equation*}

\subsubsection*{13.4}

\textit{Задание.}
Пусть
\begin{equation*}
  R_{ \xi } \left( n \right) =
  \begin{cases}
    5, \qquad n = 0, \\
    2, \qquad \left| n \right| = 1, \\
    0, \qquad \left| n \right| > 1.
  \end{cases}
\end{equation*}
Найдите оптимальную линейную оценку $ \xi_n$ при $ \xi^0 = \left( \dotsc, \xi_{-1}, \xi_0 \right) $.

\textit{Решение.}
Нужно решить задачу прогноза, то есть найти $ \hat{ \xi }_n$.

Знаем, что
\begin{equation*}
  \xi_n =
  \sum \limits_{k = 0}^{ \infty } a_k \varepsilon_{n - k}.
\end{equation*}

Чтобы обеспечить условие 3, возьмём $a_k = 0, \, k \geq 2$.

Условие номер 1 означает, что $a_0^2 + a_1^2 = 5$, а условие 2 означает, что $a_0 a_1 = 2$.

Отсюда
\begin{equation*}
  a_0 =
  \frac{2}{a_1}.
\end{equation*}

Подставим это в первое уравнение
\begin{equation*}
  \frac{4}{a_1^2} + a_1^2 = 5.
\end{equation*}

Умножим на $a_1^2$ и получим $a_1^4 - 5a_1^2 + 4 = 0$.

Сделаем замену $a_1^2 = t$ и подставим её в уравнение $t^2 - 5t + 4 = 0$.

По теореме Виета
\begin{equation*}
  \begin{cases}
    t_1 + t_2 = 5, \\
    t_1 \cdot t_2 = 4,
  \end{cases}
\end{equation*}
откуда $t_1 = 1, t_2 = 4$.

Тогда $a_1 = \pm 1, \pm 2, \, a_0 = \pm 2, \pm 1$.

Имеем представление $ \xi_n = 2 \varepsilon_n + \varepsilon_{n - 1}$, откуда
\begin{equation*}
  \varepsilon_n =
  \frac{1}{2} \cdot \xi_n - \frac{1}{2} \cdot \varepsilon_{n - 1} =
  \sum \limits_{k = 0}^{ \infty } \left( -1 \right)^k \cdot \frac{1}{2^{k + 1}} \cdot \xi_{n - k}.
\end{equation*}

Тогда прогноз равен $ \hat{ \xi }_n = 0, \, n \geq 2$ и
\begin{equation*}
  \hat{ \xi_1} =
  \varepsilon_0 =
  \sum \limits_{k = 0}^{ \infty } \frac{ \left( -1 \right)^k}{2^{k + 1}} \cdot \xi_{-k}.
\end{equation*}

\addcontentsline{toc}{section}{Домашнее задание}
\section*{Домашнее задание}

\subsubsection*{13.8}

\textit{Задание.}
Найдите оптимальную линейную оценку $ \xi_n, \, n \geq 1$ при
\begin{equation*}
  \xi^0 =
  \left( \dotsc, \xi_{-1}, \xi_0 \right)
\end{equation*}
и погрешность прогноза, если
\begin{enumerate}[label=\alph*)]
  \item $ \xi_n = 10 \varepsilon_n + 3 \varepsilon_{n - 1} - \varepsilon_{n - 2}$;
  \item $ \xi_n = 3 \varepsilon_n + 11 \varepsilon_{n - 1} - 4 \varepsilon_{n - 2}$.
\end{enumerate}

\textit{Решение.}
Оптимальная оценка $ \hat{ \xi }_n$~---~это проекция $ \xi_n$ на $H_0^{ \xi }$.

Нужно знать базис в пространстве $H_0^{ \xi }$.

Если $ \varepsilon_n \in H_0^{ \xi }$,
то $ \varepsilon_0, \varepsilon_{-1}, \varepsilon_{-2}, \dotsc $~---~это
и будет ортонормированный базис в $H_0^{ \xi }$.
Можно ли $ \varepsilon_n$ переписать через $ \xi_n$?
\begin{enumerate}[label=\alph*)]
  \item Выразим из соотношения, заданного в условии
  \begin{equation*}
    10 \varepsilon_n =
    \xi_n - 3 \varepsilon_{n - 1} + \varepsilon_{n - 2},
  \end{equation*}
  откуда
  \begin{equation*}
    \varepsilon_n =
    \frac{1}{10} \cdot \xi_n - \frac{3}{10} \cdot \varepsilon_{n - 1} +
    \frac{1}{10} \cdot \varepsilon_{n - 2} =
  \end{equation*}
  Подставим выражение для $ \varepsilon_{n - 1}$ и раскроем скобки
  \begin{equation*}
    = \frac{1}{10} \cdot \xi_n - \frac{3}{10^2} \cdot \xi_{n - 1} +
    \frac{9}{10^2} \cdot \varepsilon_{n - 2} - \frac{3}{10^2} \cdot \varepsilon_{n - 3} +
    \frac{1}{10} \cdot \varepsilon_{n - 2} =
  \end{equation*}
  Приведём подобные
  \begin{equation*}
    = \frac{1}{10} \cdot \xi_n - \frac{3}{10^2} \cdot \xi_{n - 1} +
    \frac{19}{10^2} \cdot \varepsilon_{n - 2} - \frac{3}{10^3} \varepsilon_{n - 3} =
    \dotsc =
  \end{equation*}
  После $N$ шагов получим
  \begin{equation*}
    = \sum \limits_{k = 0}^N \left( -1 \right)^k \cdot \frac{c_k}{10^{k + 1}} \cdot \xi_{n - k} +
    \frac{ \varepsilon_{n - N}}{10^N} \cdot c_N \cdot \left( -1 \right)^N.
  \end{equation*}

  Второе слагаемое стремится к нулю при $N \to \infty $, потому что его длина~---~это
  $c_N \cdot 10^{-N}$.

  Тогда
  \begin{equation*}
    \varepsilon_n =
    \sum \limits_{k = 0}^{ \infty }
      \frac{ \left( -1 \right)^k \cdot c_k}{10^{k + 1}} \cdot \xi_{n - k} \in
    H_0^{ \xi }.
  \end{equation*}

  Вывод такой, что у нас появился ортонормированный базис в $H_0^{ \xi }$,
  то есть $ \left\{ \varepsilon_k, \, k \leq 0 \right\} $.

  Значит, мы можем посчитать проекцию
  \begin{equation*}
    \hat{ \xi }_n =
    \sum \limits_{k = -\infty }^0 \left( \xi_n, \varepsilon_k \right) \varepsilon_k.
  \end{equation*}

  Чтобы получить ответ, нужно найти ковариацию, то есть
  \begin{equation*}
    \left( \xi_n, \varepsilon_k \right) =
    \left( 10 \varepsilon_n + 3 \varepsilon_{n - 1} - \varepsilon_{n - 2}, \varepsilon_k \right) =
  \end{equation*}
  Раскроем скобки
  \begin{equation*}
    = 10 \left( \varepsilon_n, \varepsilon_k \right) +
    3 \left( \varepsilon_{n - 1}, \varepsilon_k \right) -
    \left( \varepsilon_{n - 2}, \varepsilon_k \right) =
  \end{equation*}
  Первое слагаемое равно нулю
  \begin{equation*}
    = \begin{cases}
      3, \qquad n = 1, k = 0, \\
      -1, \qquad n = 1, k = -1, \\
      -1, \qquad n = 2, k = 0, \\
      0, \qquad in \, other \, cases.
    \end{cases}
  \end{equation*}

  Говорили, что $n \geq 1$, а $k \leq 0$.

  Теперь получим ответ.
  Если хотим спрогнозировать $ \xi_n$ при $n > 2$, то $ \hat{ \xi }_n = 0$.
  Значит, ошибка прогноза
  \begin{equation*}
    M \left( \xi_n - \hat{ \xi }_n \right)^2 =
    M \xi_n^2 =
    M \left( 10 \varepsilon_n + 3 \varepsilon_{n - 1} - \varepsilon_{n - 2} \right)^2 =
  \end{equation*}
  По теореме Пифагора
  \begin{equation*}
    = 100 + 9 + 1 =
    110.
  \end{equation*}

  Если $n = 1$, то
  \begin{equation*}
    \hat{ \xi }_1 =
    3 \varepsilon_0 - \varepsilon_{-1} =
    3 \sum \limits_{k = 0}^{ \infty }
      \frac{ \left( -1 \right)^k \cdot c_k}{10^{k + 1}} \cdot \xi_{-k} -
    \sum \limits_{k = 0}^{ \infty }
      \frac{ \left( -1 \right)^k \cdot c_k}{10^{k + 1}} \cdot \xi_{-1 - k} =
  \end{equation*}
  Запишем под одну сумму
  \begin{equation*}
    = \sum \limits_{k = 0}^{ \infty } \frac{ \left( -1 \right)^k \cdot c_k}{10^{k + 1}}
    \left( 3 \xi_{-k} - \xi_{-1 - k} \right).
  \end{equation*}

  Значит, ошибка прогноза
  \begin{equation*}
    M \left( \xi_1 - \hat{ \xi }_1 \right)^2 =
    M \left(
      10 \varepsilon_1 + 3 \varepsilon_0 - \varepsilon_{-1} - 3 \varepsilon_0 + \varepsilon_{-1}
    \right)^2 =
    M \left( 10 \varepsilon_1 \right)^2 =
    100.
  \end{equation*}

  Если $n = 2$, то
  \begin{equation*}
    \hat{ \xi }_2 = - \varepsilon_0 =
    - \sum \limits_{k = 0}^{ \infty }
      \frac{ \left( -1 \right)^k \cdot c_k}{10^{k + 1}} \cdot \xi_{-k}.
  \end{equation*}

  Значит, ошибка прогноза
  \begin{equation*}
    M \left( \xi_2 - \hat{ \xi }_2 \right)^2 =
    M \left( 10 \varepsilon_2 + 3 \varepsilon_1 - \varepsilon_0 + \varepsilon_0 \right)^2 =
    M \left( 10 \varepsilon_2 + 3 \varepsilon_1 \right)^2 =
    109.
  \end{equation*}
  \item Выразим из соотношения, которое задано в условии,
  \begin{equation*}
    3 \varepsilon_n =
    \xi_n - 11 \varepsilon_{n - 1} + 4 \varepsilon_{n - 2},
  \end{equation*}
  откуда
  \begin{equation*}
    \varepsilon_n =
    \frac{1}{3} \cdot \xi_n - \frac{11}{3} \cdot \varepsilon_{n - 1} +
    \frac{4}{3} \cdot \varepsilon_{n - 2} =
  \end{equation*}
  Подставим выражение для $ \varepsilon_{n - 1}$.
  Получим
  \begin{equation*}
    = \frac{1}{3} \cdot \xi_n - \frac{11}{3} \left(
      \frac{1}{3} \cdot \xi_{n - 1} - \frac{11}{3} \cdot \varepsilon_{n - 2} +
      \frac{4}{3} \cdot \varepsilon_{n - 3}
    \right) + \frac{4}{3} \cdot \varepsilon_{n - 2} =
  \end{equation*}
  Раскроем скобки
  \begin{equation*}
    = \frac{1}{3} \cdot \xi_n - \frac{11}{3^2} \cdot \xi_{n - 1} +
    \frac{133}{3^2} \cdot \varepsilon_{n - 2} - \frac{44}{3^3} \cdot \varepsilon_{n - 3} =
    \dotsc =
  \end{equation*}
  После $N$ шагов получим
  \begin{equation*}
    = \sum \limits_{k = 0}^N \left( -1 \right)^k \cdot \frac{1}{3^{k + 1}} \cdot c_k \xi_{n - k} +
    \frac{ \varepsilon_{n - N}}{3^N} \cdot c_n \left( -1 \right)^N.
  \end{equation*}

  Второе слагаемое стремится к нулю при $N \to \infty $,
  потому что его длина~---~это $c^N \cdot 3^{-N}$.

  Тогда
  \begin{equation*}
    \varepsilon_n =
    \sum \limits_{k = 0}^{ \infty } \frac{ \left( -1 \right)^k}{3^{k + 1}} \cdot c_k \xi_{n - k} \in
    H_0^{ \xi }.
  \end{equation*}

  Вывод такой, что у нас появился ортонормированный базис в
  $H_0^{ \xi }$, то есть $ \left\{ \varepsilon_k, \, k \leq 0 \right\} $.

  Значит, мы можем найти проекцию
  \begin{equation*}
    \hat{ \xi }_n =
    \sum \limits_{k = -\infty }^0 \left( \xi_n, \varepsilon_k \right) \varepsilon_k.
  \end{equation*}

  Чтобы получить ответ, нужно найти ковариацию, то есть
  \begin{equation*}
    \left( \xi_n, \varepsilon_k \right) =
    \left( 4 \varepsilon_n + 11 \varepsilon_{n - 1} - 4 \varepsilon_{n - 2}, \varepsilon_k \right) =
  \end{equation*}
  Раскроем скобки
  \begin{equation*}
    = 3 \left( \varepsilon_n, \varepsilon_k \right) +
    11 \left( \varepsilon_{n - 1}, \varepsilon_k \right) -
    4 \left( \varepsilon_{n - 2}, \varepsilon_k \right) =
  \end{equation*}
  Первое слагаемое равно нулю
  \begin{equation*}
    = \begin{cases}
      11, \qquad n = 1, k = 0, \\
      -4, \qquad n = 1, k = -1, \\
      -4, \qquad n = 2, k = 0, \\
      0, \qquad otherwise.
    \end{cases}
  \end{equation*}

  Говорили, что $n \geq 1, \, k \leq 0$.

  Теперь получим ответ.
  Если хотим спрогнозировать $ \xi_n$ при $n \geq 3$, то $ \hat{ \xi }_n = 0$.
  Значит, ошибка прогноза
  \begin{equation*}
    M \left( \xi_n - \hat{ \xi }_n \right)^2 =
    M \xi_n^2 =
    M \left( 3 \varepsilon_n + 11 \varepsilon_{n - 1} - 4 \varepsilon_{n - 2} \right)^2 =
  \end{equation*}
  По теореме Пифагора
  \begin{equation*}
    = 9 + 121 + 16 =
    146.
  \end{equation*}

  Если $n = 1$, то
  \begin{equation*}
    \hat{ \xi }_1 =
    11 \varepsilon_0 - 4 \varepsilon_{-1} =
    11 \sum \limits_{k = 0}^{ \infty } \frac{ \left( -1 \right)^k}{3^{k + 1}} \cdot c_k \xi_{-k} -
    4 \sum \limits_{k = 0}^{ \infty }
      \frac{ \left( -1 \right)^k}{3^{k + 1}} \cdot c_k \xi_{-1 - k} =
  \end{equation*}
  Запишем под одной суммой
  \begin{equation*}
    = \sum \limits_{k = 0}^{ \infty } \frac{ \left( -1 \right)^k}{3^{k + 1}} \cdot c_k
    \left( 11 \xi_{-k} - 4 \xi_{-1 - k} \right).
  \end{equation*}

  Значит, ошибка прогноза
  \begin{equation*}
    M \left( \xi_1 - \hat{ \xi }_1 \right)^2 =
    M \left(
      3 \varepsilon_1 + 11 \varepsilon_0 - 4 \varepsilon_{-1} - 11 \varepsilon_0 +
      4 \varepsilon_{-1}
    \right)^2 =
    M \left( 3 \varepsilon_1 \right)^2 =
    9.
  \end{equation*}

  Если $n = 2$, то
  \begin{equation*}
    \hat{ \xi }_2 =
    -4 \varepsilon_0 =
    -4 \sum \limits_{k = 0}^{ \infty } \frac{ \left( -1 \right)^k}{3^{k + 1}} \cdot c_k \xi_{-k}.
  \end{equation*}

  Значит, ошибка прогноза
  \begin{equation*}
    M \left( \xi_2 - \hat{ \xi }_2 \right)^2 =
    M \left( 3 \varepsilon_2 + 11 \varepsilon_1 - 4 \varepsilon_0 + 4 \varepsilon_0 \right)^2 =
    M \left( 3 \varepsilon_2 + 11 \varepsilon_1 \right)^2 =
    130.
  \end{equation*}
\end{enumerate}
Решили задачу прогноза.

\subsubsection*{13.9}

\textit{Задание.}
Спектральна мера стационарной последовательности $ \left\{ \xi_n \right\}_{n \in \mathbb{Z}}$
подаётся в виде
\begin{equation*}
  \mu \left( d \lambda \right) =
  \delta_0 \left( d \lambda \right) +
  \frac{1}{2 \pi } \cdot \left| 2 - e^{-i \lambda } \right|^2 d \lambda.
\end{equation*}
Найдите регулярную компоненту в разложении Вольда для последовательности
$ \left\{ \xi_n \right\}_{n \in \mathbb{Z}}$.

\textit{Решение.}
Допустим, что
\begin{equation*}
  \mu^{regular} \left( d \lambda \right) =
  \frac{1}{2 \pi } \cdot \left| 2 - e^{-i \lambda } \right|^2 d \lambda, \,
  \mu^{singular} \left( d \lambda \right) = \delta_0 \left( d \lambda \right).
\end{equation*}
Тогда
\begin{gather*}
  R^{singular} \left( n \right) =
  \frac{1}{2 \pi }
  \int \limits_{-\pi }^{ \pi } e^{i \lambda n} \mu^{singular} \left( d \lambda \right) =
  \frac{1}{2 \pi } \int \limits_{-\pi }^{ \pi } e^{i \lambda n} \delta_0 \left( d \lambda \right) =
  1, \\
  R^{regular} \left( n \right) =
  \frac{1}{2 \pi } \int \limits_{-\pi }^{ \pi }
    e^{i \lambda n} \cdot \frac{1}{2 \pi } \cdot \left| 2 - e^{-i \lambda } \right|^2
  d \lambda =
\end{gather*}
Выпишем отдельно
\begin{gather*}
  \left| 2 - e^{-i \lambda } \right|^2 =
  \left| 2 - \cos \lambda + i \sin \lambda \right|^2 =
  \left(
    2 - \cos \lambda + i \sin \lambda \right) \left( 2 - \cos \lambda - i \sin \lambda
  \right) = \\
  = 4 - 2 \cos \lambda - 2i \sin \lambda - 2 \cos \lambda + \cos^2 \lambda +
  i \cos \lambda \cdot \sin \lambda + 2i \sin \lambda - \\
  - i \sin \lambda \cdot \cos \lambda + \sin^2 \lambda =
  4 - 4 \cos \lambda + 1 =
  5 - 4 \cos \lambda.
\end{gather*}
Тогда
\begin{gather*}
  = \frac{1}{4 \pi }
  \int \limits_{-\pi }^{ \pi } e^{i \lambda n} \left( 5 - 4 \cos \lambda \right) d \lambda =
  \frac{1}{4 \pi } \int \limits_{-\pi }^{ \pi }
    e^{i \lambda n} \left( 5 - 2e^{i \lambda } - 2e^{-i \lambda } \right)
  d \lambda = \\
  = \begin{cases}
    \frac{5}{4 \pi }, \qquad n = 0, \\
    0, \qquad n \neq 0.
  \end{cases}
\end{gather*}

Поскольку свойство быть сингулярной или регулярной последовательностью полностью определяется
ковариационной функцией последовательности, то, если найдём такую сингулярную последовательность,
что $R \left( n \right) = 1$, и регулярную последовательность с
\begin{equation*}
  R \left( n \right) =
  \begin{cases}
    \frac{5}{4 \pi }, \qquad n = 0, \\
    0, \qquad n \neq 0,
  \end{cases}
\end{equation*}
то наше начальное предположение будет верным.

Итак,
\begin{enumerate}
  \item $ \xi_n = \xi_{n + 1}, \,
    \xi_n \sim N \left( 0, 1 \right), \,
    cov \left( \xi_n, \xi_m \right) = M \xi_n^2 = 1$;
  \item пусть $ \left\{ \varepsilon_n \right\}_{n \in \mathbb{Z}}$~---~белый шум.
  Тогда
  \begin{equation*}
    \xi_n = \frac{ \sqrt{5}}{2 \sqrt{ \pi }} \cdot \varepsilon_n,
  \end{equation*}
  ковариация равна
  \begin{gather*}
    cov \left( \xi_n, \xi_m \right) =
    cov \left(
      \frac{ \sqrt{5}}{2 \sqrt{ \pi }} \cdot \varepsilon_n,
      \frac{ \sqrt{5}}{2 \sqrt{ \pi }} \cdot \varepsilon_m
    \right) =
    \frac{5}{4 \pi } \cdot cov \left( \varepsilon_n, \varepsilon_m \right) = \\
    = \begin{cases}
      \frac{5}{4 \pi }, \qquad n = m, \\
      0, \qquad n \neq m.
    \end{cases}
  \end{gather*}
\end{enumerate}

Значит,
регулярная компонента в разложении Вольда для $ \left\{ \xi_n \right\}_{n \in \mathbb{Z}}$~---~это
\begin{equation*}
  \xi_n^{regular} =
  \frac{ \sqrt{5}}{2 \sqrt{ \pi }} \cdot \varepsilon_n.
\end{equation*}

\subsubsection*{13.10}

\textit{Задание.}
Пусть
$ \hat{ \xi }_n = M \left( \xi_n \; \middle| \; H_0 \left( \xi \right) \right), \,
  \sigma_n^2 = M \left( \xi_n - \hat{ \xi }_n \right)^2$.
Докажите, что если $ \sigma_n^2 = 0$ для некоторого $n \geq 1$, то последовательность сингулярна;
если же $ \sigma_n^2 \to R \left( 0 \right) $ при $n \to \infty $, то последовательность регулярна.

\textit{Решение.}
$ \sigma_n^2 =
  M \left( \xi_n - \hat{ \xi }_n \right)^2 =
  M \left[ \xi_n - Pr_{H_0^{ \xi }} \left( \xi_n \right) \right]^2$.

Проверим сигрулярность.
$M \left[ \xi_n - Pr_{H_0^{ \xi }} \left( \xi_n \right) \right]^2 = 0 \Rightarrow
  \xi_n - Pr_{H_0^{ \xi }} \left( \xi_n \right) = 0$
при некотором $n \geq 1$.

Тогда $ \xi_n = Pr_{H_0^{ \xi }} \left( \xi_n \right) $.

По определению
$H_n^{ \xi } =
  \overline{LS \left\{ \xi_k, \, k \leq n \right\} } =
  H_{n - 1}^{ \xi }$,
так как
\begin{equation*}
  \xi_n \in H_0^{ \xi } \Rightarrow
  \xi_n \in H_{n - 1}^{ \xi },
\end{equation*}
следовательно, $ \xi_n$~---~сингулярная.

Проверим регулярность.
$M \left( \xi_n - \hat{ \xi }_n \right)^2 \to R \left( 0 \right) = M \xi_N^2, \,
  n \to \infty, \,
  N$~---~фиксировано.

\begin{gather*}
  M \left( \xi_n - \hat{ \xi }_n \right)^2 =
  M \left(
    \xi_n^{singular} - \sum \limits_{k \geq 0} c_k \varepsilon_{n - k} - \xi_n^{singular} +
    \sum \limits_{k \geq N} c_k \varepsilon_{n - k}
  \right)^2 = \\
  = M \left( \sum \limits_{k = 0}^{N - 1} c_k \varepsilon_{n - k} \right)^2 =
  \sum \limits_{k = 0}^{N - 1} \left| c_k \right|^2.
\end{gather*}

Таким образом,
\begin{equation*}
  M \xi_N^2 =
  M \left( \xi_N^{singular} \right)^2 + \sum \limits_{k \geq 0} \left| c_k \right|^2 \geq
  \sum \limits_{k \geq 0} \left| c_k \right|^2.
\end{equation*}

Сходимость есть только когда
$M \left( \xi_N^{singular} \right)^2 = 0 \,
  \forall N \Rightarrow
  \xi_n^{singular} = 0$,
следовательно, $ \xi $~---~регулярная.
